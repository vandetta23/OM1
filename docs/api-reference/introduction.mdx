---
title: Introduction
description: "Welcome to the OpenMind API Reference"
---

OpenMind integrates with multiple LLM providers to offer a diverse range of features. This API reference provides details on endpoints, parameters, and responses, enabling efficient interaction with the OpenMind API.

## API Keys

OpenMind requires an API key to authenticate requests. You can obtain an API key by signing up for an account on the [OpenMind portal](https://portal.openmind.org). The API key must be included in the `Authorization` or `x-api-key` header of each request, used to authenticate your requests and track usage quotas.

**Keep your API key confidential**. Never share it with others or expose it in client-side code, such as in browsers or apps.

Remember to include your API key in the `Authorization` or `x-api-key` header of each request. For example:

```bash
x-api-key: YOUR_API_KEY
# or,
Authorization: Bearer YOUR_API_KEY
```

For websocket connections, include the API key in the query string. For example: `wss://api.openmind.org?api_key=<YOUR_API_KEY>`.

## API Pricing

Access our API, scale usage as needed, and stay in control of costs. For detailed API pricing, refer [here](./api_pricing)

- High-speed requests
- Cutting-edge large models
- Integrated modules for multiple robots

For developer walkthrough and support reach out to: support@openmind.org

### LLM Models

| Service                               | Input Price (per 1M tokens) | Output Price (per 1M tokens) |
|---------------------------------------|-----------------------------|------------------------------|
| OpenAI GPT-4o                         | 8333 OMCU                   | 33333 OMCU                   |
| OpenAI GPT-4o-mini                    | 500 OMCU                    | 2000 OMCU                    |
| OpenAI GPT-4.1                        | 6667 OMCU                   | 26667 OMCU                   |
| OpenAI GPT-4.1-mini                   | 1333 OMCU                   | 5333 OMCU                    |
| OpenAI GPT-4.1-nano                   | 333 OMCU                    | 1333 OMCU                    |
| OpenAI GPT-5                          | 4167 OMCU                   | 33333 OMCU                   |
| OpenAI GPT-5-mini                     | 833 OMCU                    | 3333 OMCU                    |
| OpenAI GPT-5-nano                     | 167 OMCU                    | 667 OMCU                     |
| DeepSeek Chat                         | 467 OMCU                    | 933 OMCU                     |
| Gemini 2.5 Flash                      | 1000 OMCU                   | 8333 OMCU                    |
| Gemini 2.5 Flash Lite                 | 333 OMCU                    | 1333 OMCU                    |
| Gemini 2.5 Pro                        | 8333 OMCU                   | 50K OMCU                     |
| Gemini 3 Pro                          | 13333 OMCU                  | 60K OMCU                     |
| Gemini 3 Flash                        | 3333 OMCU                   | 10K OMCU                     |
| grok-2-latest                         | 6667 OMCU                   | 33333 OMCU                   |
| grok-3-beta                           | 10k OMCU                    | 50k OMCU                     |
| grok-4-latest                         | 10k OMCU                    | 50k OMCU                     |
| grok-4                                | 10k OMCU                    | 50k OMCU                     |
| qwen3-30b-a3b-instruct-2507 (Near AI) | 500 OMCU                    | 1500 OMCU                    |
| qwen-2.5-7b-instruct (Near AI)        | 133 OMCU                    | 333 OMCU                     |
| qwen2.5-vl-72b-instruct (Near AI)     | 1967 OMCU                   | 1967 OMCU                    |
| llama-3.1-70b-instruct (Meta Llama)   | 333 OMCU                    | 933 OMCU                     |
| llama-3.3-70b-instruct (Meta Llama)   | 3K OMCU                     | 3K OMCU                      |
| anthropic/claude-sonnet-4.5           | 10K OMCU                    | 50K OMCU                     |
| anthropic/claude-opus-4.1             | 50K OMCU                    | 250K OMCU                    |

<Note>
Near AI models are hosted and served by [Near AI](https://cloud.near.ai).
Meta Llama and Anthropic models are hosted and served by [Openrouter](https://openrouter.ai/).
For free local inference, [Ollama](https://ollama.ai) supports models like llama3.2, mistral, and phi3 with no API costs.
</Note>

### TTS Models (Text to Speech)

| Service              | Price (per 1M characters) |
|----------------------|---------------------------|
| Eleven Labs          | 10k OMCU                  |
| Riva                 | 3333 OMCU                 |

We will support more models in the future. Contact us if you have any questions or need a custom solution.

### ASR Models (Speech to Text)

| Service              | Price (per 1 minute) |
|----------------------|----------------------|
| Google ASR           | 17 OMCU              |
